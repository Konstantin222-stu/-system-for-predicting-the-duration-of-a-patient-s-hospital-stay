import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib

matplotlib.use('Agg')

import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import (accuracy_score, classification_report,
                             confusion_matrix, f1_score, roc_auc_score,
                             roc_curve, precision_recall_curve)
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import joblib
import warnings
import os

warnings.filterwarnings('ignore')

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∏–ª—å –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.style.use('default')
sns.set_palette("husl")


class DiabetesPredictor:
    def __init__(self):
        self.model = None
        self.preprocessor = None
        self.feature_names = None
        self.optimal_threshold = 0.5
        self.models_results = {}

    def load_data(self, file_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV"""
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV...")
        try:
            self.df = pd.read_csv(file_path)
            self.df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = self.df[
                ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.nan)
            self.df = self.df.fillna(self.df.median())

            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {self.df.shape}")
            print("\nüìä –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
            print(self.df.head())
            print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(self.df.describe())
            print(f"\nüéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:")
            print(self.df['Outcome'].value_counts())
            print(f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {self.df['Outcome'].value_counts(normalize=True)}")
            return self.df
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None

    def explore_data(self):
        """–í–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
        print("–í–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
        try:
            plt.figure(figsize=(15, 5))
            plt.subplot(1, 2, 1)
            sns.histplot(data=self.df, x='Age', hue='Outcome', multiple='stack', bins=30)
            plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞ –ø–æ –∏—Å—Ö–æ–¥—É')
            plt.xlabel('–í–æ–∑—Ä–∞—Å—Ç')
            plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')

            plt.subplot(1, 2, 2)
            sns.boxplot(x='Outcome', y='Glucose', data=self.df)
            plt.title('–£—Ä–æ–≤–µ–Ω—å –≥–ª—é–∫–æ–∑—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ö–æ–¥–∞')
            plt.xlabel('–ò—Å—Ö–æ–¥ (0: –Ω–µ—Ç, 1: –µ—Å—Ç—å –¥–∏–∞–±–µ—Ç)')
            plt.ylabel('–£—Ä–æ–≤–µ–Ω—å –≥–ª—é–∫–æ–∑—ã')

            plt.tight_layout()
            plt.savefig('diabetes_data_analysis.png')
            plt.show()
            print("‚úÖ –í–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ diabetes_data_analysis.png")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")

    def prepare_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        try:
            target_col = 'Outcome'
            y = self.df[target_col]
            X = self.df.drop(columns=[target_col])
            self.feature_names = X.columns.tolist()
            numerical_features = X.columns.tolist()

            self.preprocessor = ColumnTransformer(
                transformers=[
                    ('num', StandardScaler(), numerical_features)
                ])

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y)

            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã. –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape}")
            return X_train, X_test, y_train, y_test, self.feature_names
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None, None, None, None, None

    def train_models(self, X_train, X_test, y_train, y_test):
        """–û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        print("–û–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π...")

        models = {
            'Logistic Regression': LogisticRegression(random_state=42),
            'Random Forest': RandomForestClassifier(random_state=42),
            'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss')  # <-- –ò–ó–ú–ï–ù–ï–ù–ò–ï –ó–î–ï–°–¨
        }

        for name, model in models.items():
            print(f"\n‚ñ∂Ô∏è –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ {name}...")
            pipeline = Pipeline(steps=[('preprocessor', self.preprocessor),
                                       ('classifier', model)])
            pipeline.fit(X_train, y_train)
            self.evaluate_model(pipeline, X_test, y_test, model_name=name)
            self.models_results[name] = pipeline

        return self.models_results

    def tune_best_model(self, X_train, y_train):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (XGBoost)"""
        print("\n–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (XGBoost)...")

        pipeline = ImbPipeline(steps=[
            ('preprocessor', self.preprocessor),
            ('smote', SMOTE(random_state=42)),
            ('classifier', XGBClassifier(random_state=42, eval_metric='logloss'))  # <-- –ò–ó–ú–ï–ù–ï–ù–ò–ï –ó–î–ï–°–¨
        ])

        param_grid = {
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [3, 5, 7],
            'classifier__learning_rate': [0.01, 0.1, 0.2]
        }

        search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)
        search.fit(X_train, y_train)

        self.model = search.best_estimator_
        self.optimal_threshold = self.find_optimal_threshold(self.model, X_train, y_train)

        print("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        print(f"   > –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {search.best_params_}")
        print(f"   > –õ—É—á—à–∏–π F1-Score: {search.best_score_:.4f}")
        print(f"   > –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {self.optimal_threshold:.4f}")

    def train_stacking_ensemble(self, X_train, y_train):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è —Å—Ç–µ–∫–∏–Ω–≥–∞"""
        print("\n‚ñ∂Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è —Å—Ç–µ–∫–∏–Ω–≥–∞...")

        # –ë–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
        estimators = [
            ('lr', LogisticRegression(random_state=42)),
            ('rf', RandomForestClassifier(random_state=42)),
            ('xgb', XGBClassifier(random_state=42, eval_metric='logloss'))  # <-- –ò–ó–ú–ï–ù–ï–ù–ò–ï –ó–î–ï–°–¨
        ]

        # –ú–µ—Ç–∞-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)
        stacking_clf = StackingClassifier(
            estimators=estimators,
            final_estimator=LogisticRegression(),
            cv=5,
            n_jobs=-1
        )

        pipeline = ImbPipeline(steps=[
            ('preprocessor', self.preprocessor),
            ('smote', SMOTE(random_state=42)),
            ('classifier', stacking_clf)
        ])

        pipeline.fit(X_train, y_train)
        self.model = pipeline
        self.optimal_threshold = self.find_optimal_threshold(self.model, X_train, y_train)

        print("‚úÖ –ê–Ω—Å–∞–º–±–ª—å —Å—Ç–µ–∫–∏–Ω–≥–∞ –æ–±—É—á–µ–Ω.")
        print(f"   > –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è: {self.optimal_threshold:.4f}")

    def find_optimal_threshold(self, model, X_train, y_train):
        """–ù–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        y_scores = model.predict_proba(X_train)[:, 1]
        precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)
        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)
        f1_scores = np.nan_to_num(f1_scores)
        optimal_threshold = thresholds[np.argmax(f1_scores)]
        return optimal_threshold

    def evaluate_model(self, model, X_test, y_test, model_name="–ú–æ–¥–µ–ª—å"):
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"""
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        optimal_threshold = self.find_optimal_threshold(model, X_test, y_test)
        y_pred = (y_pred_proba >= optimal_threshold).astype(int)

        print(f"\n‚ñ∂Ô∏è –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è {model_name}:")
        print(classification_report(y_test, y_pred))

        print(f"‚ñ∂Ô∏è –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è {model_name}:")
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(6, 5))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
        plt.title(f'–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è {model_name}')
        plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ')
        plt.ylabel('–ò—Å—Ç–∏–Ω–∞')
        plt.savefig(f'diabetes_{model_name.replace(" ", "_")}_confusion_matrix.png')
        plt.show()

        roc_auc = roc_auc_score(y_test, y_pred_proba)
        print(f"   > –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy_score(y_test, y_pred):.4f}")
        print(f"   > F1-Score: {f1_score(y_test, y_pred):.4f}")
        print(f"   > ROC-AUC: {roc_auc:.4f}")
        print(f"   > –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {optimal_threshold:.4f}")

        return {'roc_auc': roc_auc, 'model': model}

    def final_evaluation(self, X_test, y_test):
        """–û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ–¥–Ω–æ–º –≥—Ä–∞—Ñ–∏–∫–µ"""
        print("\n‚ñ∂Ô∏è –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ ROC-–∫—Ä–∏–≤–æ–π –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π...")
        plt.figure(figsize=(8, 6))

        for name, model_pipeline in self.models_results.items():
            y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1]
            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
            roc_auc = roc_auc_score(y_test, y_pred_proba)
            plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å
        final_ensemble_proba = self.model.predict_proba(X_test)[:, 1]
        final_fpr, final_tpr, _ = roc_curve(y_test, final_ensemble_proba)
        final_auc = roc_auc_score(y_test, final_ensemble_proba)
        plt.plot(final_fpr, final_tpr, 'k--', label=f'–ê–Ω—Å–∞–º–±–ª—å (AUC = {final_auc:.2f})', linewidth=2.5)

        plt.plot([0, 1], [0, 1], 'r--', label='–°–ª—É—á–∞–π–Ω–∞—è –º–æ–¥–µ–ª—å')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC-–∫—Ä–∏–≤–∞—è –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π')
        plt.legend()
        plt.savefig('diabetes_all_models_roc_curve.png')
        plt.show()
        print("‚úÖ –û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ diabetes_all_models_roc_curve.png")

    def feature_importance(self, feature_names):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        print("\n–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        if self.model and hasattr(self.model.named_steps['classifier'], 'final_estimator_'):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ü–µ–Ω—â–∏–∫–∞ —Å—Ç–µ–∫–∏–Ω–≥–∞
            final_estimator = self.model.named_steps['classifier'].final_estimator_
            if hasattr(final_estimator, 'coef_'):
                importances = final_estimator.coef_[0]
            elif hasattr(final_estimator, 'feature_importances_'):
                importances = final_estimator.feature_importances_
            else:
                print("‚ùå –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ü–µ–Ω—â–∏–∫–∞.")
                return

            feature_importance_df = pd.DataFrame({
                'Feature': ['LR', 'RF', 'XGB'],
                'Importance': importances
            }).sort_values(by='Importance', ascending=False)

            plt.figure(figsize=(10, 6))
            sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
            plt.title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è')
            plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
            plt.ylabel('–ü—Ä–∏–∑–Ω–∞–∫')
            plt.tight_layout()
            plt.savefig('diabetes_ensemble_feature_importance.png')
            plt.show()
            print("‚úÖ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∞–Ω—Å–∞–º–±–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ diabetes_ensemble_feature_importance.png")
        else:
            print("‚ùå –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.")

    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        print("\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        joblib.dump(self.model, 'diabetes_stacking_ensemble.pkl')
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ diabetes_stacking_ensemble.pkl")


def main():
    predictor = DiabetesPredictor()
    file_path = 'diabetes.csv'

    if os.path.exists(file_path):
        print("‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º CSV —Ñ–∞–π–ª")
        df = predictor.load_data(file_path)
    else:
        print(
            "‚ùå –§–∞–π–ª diabetes.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, —á—Ç–æ –∏ —Å–∫—Ä–∏–ø—Ç.")
        return

    if df is None or df.empty:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return

    predictor.explore_data()
    X_train, X_test, y_train, y_test, feature_names = predictor.prepare_data()

    if X_train is not None:
        # –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        results = predictor.train_models(X_train, X_test, y_train, y_test)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (XGBoost) - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ
        predictor.tune_best_model(X_train, y_train)

        # –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
        predictor.train_stacking_ensemble(X_train, y_train)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∞–Ω—Å–∞–º–±–ª—è
        print("\n" + "=" * 50)
        print("–§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê –ê–ù–°–ê–ú–ë–õ–Ø –°–¢–ï–ö–ò–ù–ì–ê")
        print("=" * 50)
        predictor.evaluate_model(predictor.model, X_test, y_test, model_name="–ê–Ω—Å–∞–º–±–ª—å")
        predictor.final_evaluation(X_test, y_test)
        predictor.save_model()

    print("\n" + "=" * 50)
    print("‚úÖ –ü–†–û–¶–ï–°–° –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù")
    print("=" * 50)
    print("üìÅ –°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã:")
    print("- diabetes_data_analysis.png")
    print("- diabetes_Logistic_Regression_confusion_matrix.png")
    print("- diabetes_Random_Forest_confusion_matrix.png")
    print("- diabetes_XGBoost_confusion_matrix.png")
    print("- diabetes_–ê–Ω—Å–∞–º–±–ª—å_confusion_matrix.png")
    print("- diabetes_all_models_roc_curve.png")
    print("- diabetes_stacking_ensemble.pkl")


if __name__ == "__main__":
    main()